{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark ML imports\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StringIndexer, CountVectorizer, IDF\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.feature\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)\n",
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel\n",
    "import tempfile\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.sql.functions import col, explode, array, lit\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airline Cancellation Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data into PySpark\n",
    "df = spark.read.csv(\"/user/nhu2/airline/Data_logistics_clean.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FL_DATE', 'timestamp'),\n",
       " ('OP_CARRIER', 'string'),\n",
       " ('ORIGIN', 'string'),\n",
       " ('CRS_DEP_TIME', 'double'),\n",
       " ('CRS_ELAPSED_TIME', 'double'),\n",
       " ('CANCELLED', 'double')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data type\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to date datatype\n",
    "df = df.withColumn(\"FL_DATE\",to_date(col(\"FL_DATE\"),\"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct seasonal variable based on date \n",
    "df = df.withColumn(\"SEASON\", \\\n",
    "   when((month(df.FL_DATE) >= 3) & (month(df.FL_DATE) <= 5), lit(\"Spring\")) \\\n",
    "     .when((month(df.FL_DATE) >= 6) & (month(df.FL_DATE) <= 8), lit(\"Summer\")) \\\n",
    ".when((month(df.FL_DATE) >= 9) & (month(df.FL_DATE) <= 11), lit(\"Fall\")) \\\n",
    "     .otherwise(lit(\"Winter\")) \\\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+------------+----------------+---------+------+-------------+---------+---------+---------------+----------------+---------+\n",
      "|   FL_DATE|OP_CARRIER|ORIGIN|CRS_DEP_TIME|CRS_ELAPSED_TIME|CANCELLED|SEASON|OP_CARRIERIDX|ORIGINIDX|SEASONIDX|  OP_CARRIERVec|       ORIGINVec|SEASONVec|\n",
      "+----------+----------+------+------------+----------------+---------+------+-------------+---------+---------+---------------+----------------+---------+\n",
      "|2009-01-01|        XE|   DCA|      1100.0|            62.0|      0.0|Winter|         11.0|     22.0|      3.0|(22,[11],[1.0])|(379,[22],[1.0])|(3,[],[])|\n",
      "|2009-01-01|        XE|   EWR|      1510.0|            82.0|      0.0|Winter|         11.0|     13.0|      3.0|(22,[11],[1.0])|(379,[13],[1.0])|(3,[],[])|\n",
      "|2009-01-01|        XE|   EWR|      1100.0|            70.0|      0.0|Winter|         11.0|     13.0|      3.0|(22,[11],[1.0])|(379,[13],[1.0])|(3,[],[])|\n",
      "|2009-01-01|        XE|   DCA|      1240.0|            77.0|      0.0|Winter|         11.0|     22.0|      3.0|(22,[11],[1.0])|(379,[22],[1.0])|(3,[],[])|\n",
      "|2009-01-01|        XE|   IAD|      1715.0|           105.0|      0.0|Winter|         11.0|     27.0|      3.0|(22,[11],[1.0])|(379,[27],[1.0])|(3,[],[])|\n",
      "+----------+----------+------+------------+----------------+---------+------+-------------+---------+---------+---------------+----------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#convert relevant categorical into one hot encoded\n",
    "indexer1 = StringIndexer(inputCol=\"OP_CARRIER\", outputCol=\"OP_CARRIERIDX\").setHandleInvalid(\"skip\")\n",
    "indexer2 = StringIndexer(inputCol=\"ORIGIN\", outputCol=\"ORIGINIDX\").setHandleInvalid(\"skip\")\n",
    "indexer3 = StringIndexer(inputCol=\"SEASON\", outputCol=\"SEASONIDX\").setHandleInvalid(\"skip\")\n",
    "\n",
    "#gather all indexers as inputs to the One Hot Encoder\n",
    "inputs = [indexer1.getOutputCol(), indexer2.getOutputCol(), \\\n",
    "          indexer3.getOutputCol()]\n",
    "\n",
    "#create the one hot encoder\n",
    "encoder = OneHotEncoder(inputCols=inputs,  \\\n",
    "                                 outputCols=[\"OP_CARRIERVec\", \"ORIGINVec\", \\\n",
    "                                             \"SEASONVec\"])\n",
    "\n",
    "#run it through a pipeline\n",
    "pipeline = Pipeline(stages=[indexer1, indexer2, indexer3, encoder])\n",
    "encodedData = pipeline.fit(df).transform(df)\n",
    "\n",
    "#we have removed NAs so dont need to impute missing values.\n",
    "#pipeline = pipeline.na.fill(0) \n",
    "\n",
    "encodedData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather feature vector and identify features\n",
    "assembler = VectorAssembler(inputCols = [\"OP_CARRIERVec\", \"ORIGINVec\", \\\n",
    "                                             \"SEASONVec\"], \\\n",
    "                            outputCol = 'features')\n",
    "\n",
    "encodedData = assembler.transform(encodedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler(inputCol = \"features\", outputCol = \"scaledFeatures\", withStd = True, withMean = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scalerdf = scaler.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop categorical variables \n",
    "encodedData = encodedData.drop(\"OP_CARRIER\", \"ORIGIN\", \"SEASON\", \"OP_CARRIERIDX\", \"ORIGINIDX\", \"SEASONIDX\", \"FL_DATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>CRS_DEP_TIME</th><th>CRS_ELAPSED_TIME</th><th>CANCELLED</th><th>OP_CARRIERVec</th><th>ORIGINVec</th><th>SEASONVec</th><th>features</th></tr>\n",
       "<tr><td>1100.0</td><td>62.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[22],[1.0])</td><td>(3,[],[])</td><td>(404,[11,44],[1.0...</td></tr>\n",
       "<tr><td>1510.0</td><td>82.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[13],[1.0])</td><td>(3,[],[])</td><td>(404,[11,35],[1.0...</td></tr>\n",
       "<tr><td>1100.0</td><td>70.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[13],[1.0])</td><td>(3,[],[])</td><td>(404,[11,35],[1.0...</td></tr>\n",
       "<tr><td>1240.0</td><td>77.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[22],[1.0])</td><td>(3,[],[])</td><td>(404,[11,44],[1.0...</td></tr>\n",
       "<tr><td>1715.0</td><td>105.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[27],[1.0])</td><td>(3,[],[])</td><td>(404,[11,49],[1.0...</td></tr>\n",
       "<tr><td>1915.0</td><td>147.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[0],[1.0])</td><td>(3,[],[])</td><td>(404,[11,22],[1.0...</td></tr>\n",
       "<tr><td>1645.0</td><td>117.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[37],[1.0])</td><td>(3,[],[])</td><td>(404,[11,59],[1.0...</td></tr>\n",
       "<tr><td>1915.0</td><td>80.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[22],[1.0])</td><td>(3,[],[])</td><td>(404,[11,44],[1.0...</td></tr>\n",
       "<tr><td>1715.0</td><td>83.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[13],[1.0])</td><td>(3,[],[])</td><td>(404,[11,35],[1.0...</td></tr>\n",
       "<tr><td>1300.0</td><td>68.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[13],[1.0])</td><td>(3,[],[])</td><td>(404,[11,35],[1.0...</td></tr>\n",
       "<tr><td>1500.0</td><td>80.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[22],[1.0])</td><td>(3,[],[])</td><td>(404,[11,44],[1.0...</td></tr>\n",
       "<tr><td>2135.0</td><td>77.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[13],[1.0])</td><td>(3,[],[])</td><td>(404,[11,35],[1.0...</td></tr>\n",
       "<tr><td>1905.0</td><td>80.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[37],[1.0])</td><td>(3,[],[])</td><td>(404,[11,59],[1.0...</td></tr>\n",
       "<tr><td>2100.0</td><td>77.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[22],[1.0])</td><td>(3,[],[])</td><td>(404,[11,44],[1.0...</td></tr>\n",
       "<tr><td>905.0</td><td>127.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[1],[1.0])</td><td>(3,[],[])</td><td>(404,[11,23],[1.0...</td></tr>\n",
       "<tr><td>1000.0</td><td>159.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[13],[1.0])</td><td>(3,[],[])</td><td>(404,[11,35],[1.0...</td></tr>\n",
       "<tr><td>1230.0</td><td>149.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[1],[1.0])</td><td>(3,[],[])</td><td>(404,[11,23],[1.0...</td></tr>\n",
       "<tr><td>1343.0</td><td>160.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[13],[1.0])</td><td>(3,[],[])</td><td>(404,[11,35],[1.0...</td></tr>\n",
       "<tr><td>1630.0</td><td>152.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[1],[1.0])</td><td>(3,[],[])</td><td>(404,[11,23],[1.0...</td></tr>\n",
       "<tr><td>1930.0</td><td>173.0</td><td>0.0</td><td>(22,[11],[1.0])</td><td>(379,[13],[1.0])</td><td>(3,[],[])</td><td>(404,[11,35],[1.0...</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+------------+----------------+---------+---------------+----------------+---------+--------------------+\n",
       "|CRS_DEP_TIME|CRS_ELAPSED_TIME|CANCELLED|  OP_CARRIERVec|       ORIGINVec|SEASONVec|            features|\n",
       "+------------+----------------+---------+---------------+----------------+---------+--------------------+\n",
       "|      1100.0|            62.0|      0.0|(22,[11],[1.0])|(379,[22],[1.0])|(3,[],[])|(404,[11,44],[1.0...|\n",
       "|      1510.0|            82.0|      0.0|(22,[11],[1.0])|(379,[13],[1.0])|(3,[],[])|(404,[11,35],[1.0...|\n",
       "|      1100.0|            70.0|      0.0|(22,[11],[1.0])|(379,[13],[1.0])|(3,[],[])|(404,[11,35],[1.0...|\n",
       "|      1240.0|            77.0|      0.0|(22,[11],[1.0])|(379,[22],[1.0])|(3,[],[])|(404,[11,44],[1.0...|\n",
       "|      1715.0|           105.0|      0.0|(22,[11],[1.0])|(379,[27],[1.0])|(3,[],[])|(404,[11,49],[1.0...|\n",
       "|      1915.0|           147.0|      0.0|(22,[11],[1.0])| (379,[0],[1.0])|(3,[],[])|(404,[11,22],[1.0...|\n",
       "|      1645.0|           117.0|      0.0|(22,[11],[1.0])|(379,[37],[1.0])|(3,[],[])|(404,[11,59],[1.0...|\n",
       "|      1915.0|            80.0|      0.0|(22,[11],[1.0])|(379,[22],[1.0])|(3,[],[])|(404,[11,44],[1.0...|\n",
       "|      1715.0|            83.0|      0.0|(22,[11],[1.0])|(379,[13],[1.0])|(3,[],[])|(404,[11,35],[1.0...|\n",
       "|      1300.0|            68.0|      0.0|(22,[11],[1.0])|(379,[13],[1.0])|(3,[],[])|(404,[11,35],[1.0...|\n",
       "|      1500.0|            80.0|      0.0|(22,[11],[1.0])|(379,[22],[1.0])|(3,[],[])|(404,[11,44],[1.0...|\n",
       "|      2135.0|            77.0|      0.0|(22,[11],[1.0])|(379,[13],[1.0])|(3,[],[])|(404,[11,35],[1.0...|\n",
       "|      1905.0|            80.0|      0.0|(22,[11],[1.0])|(379,[37],[1.0])|(3,[],[])|(404,[11,59],[1.0...|\n",
       "|      2100.0|            77.0|      0.0|(22,[11],[1.0])|(379,[22],[1.0])|(3,[],[])|(404,[11,44],[1.0...|\n",
       "|       905.0|           127.0|      0.0|(22,[11],[1.0])| (379,[1],[1.0])|(3,[],[])|(404,[11,23],[1.0...|\n",
       "|      1000.0|           159.0|      0.0|(22,[11],[1.0])|(379,[13],[1.0])|(3,[],[])|(404,[11,35],[1.0...|\n",
       "|      1230.0|           149.0|      0.0|(22,[11],[1.0])| (379,[1],[1.0])|(3,[],[])|(404,[11,23],[1.0...|\n",
       "|      1343.0|           160.0|      0.0|(22,[11],[1.0])|(379,[13],[1.0])|(3,[],[])|(404,[11,35],[1.0...|\n",
       "|      1630.0|           152.0|      0.0|(22,[11],[1.0])| (379,[1],[1.0])|(3,[],[])|(404,[11,23],[1.0...|\n",
       "|      1930.0|           173.0|      0.0|(22,[11],[1.0])|(379,[13],[1.0])|(3,[],[])|(404,[11,35],[1.0...|\n",
       "+------------+----------------+---------+---------------+----------------+---------+--------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename CANCELLED to label\n",
    "encodedData = encodedData.withColumn(\"label\", encodedData.CANCELLED)\n",
    "encodedData = encodedData.drop(\"CANCELLED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CRS_DEP_TIME', 'double'),\n",
       " ('CRS_ELAPSED_TIME', 'double'),\n",
       " ('OP_CARRIERVec', 'vector'),\n",
       " ('ORIGINVec', 'vector'),\n",
       " ('SEASONVec', 'vector'),\n",
       " ('features', 'vector'),\n",
       " ('label', 'double')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 62.25153589825002\n",
      "+------------+----------------+---------------+-----------------+---------+--------------------+-----+\n",
      "|CRS_DEP_TIME|CRS_ELAPSED_TIME|  OP_CARRIERVec|        ORIGINVec|SEASONVec|            features|label|\n",
      "+------------+----------------+---------------+-----------------+---------+--------------------+-----+\n",
      "|      2130.0|            68.0|(22,[11],[1.0])| (379,[13],[1.0])|(3,[],[])|(404,[11,35],[1.0...|  0.0|\n",
      "|      1112.0|            93.0|(22,[11],[1.0])|  (379,[6],[1.0])|(3,[],[])|(404,[11,28],[1.0...|  0.0|\n",
      "|      1800.0|           112.0|(22,[11],[1.0])| (379,[45],[1.0])|(3,[],[])|(404,[11,67],[1.0...|  0.0|\n",
      "|      1340.0|            67.0|(22,[11],[1.0])| (379,[78],[1.0])|(3,[],[])|(404,[11,100],[1....|  0.0|\n",
      "|      1020.0|           144.0|(22,[11],[1.0])| (379,[28],[1.0])|(3,[],[])|(404,[11,50],[1.0...|  0.0|\n",
      "|      1750.0|            87.0|(22,[11],[1.0])|(379,[101],[1.0])|(3,[],[])|(404,[11,123],[1....|  0.0|\n",
      "|       840.0|           182.0|(22,[11],[1.0])| (379,[43],[1.0])|(3,[],[])|(404,[11,65],[1.0...|  0.0|\n",
      "|      1040.0|           137.0|(22,[11],[1.0])| (379,[13],[1.0])|(3,[],[])|(404,[11,35],[1.0...|  0.0|\n",
      "|      1435.0|            55.0|(22,[11],[1.0])|  (379,[6],[1.0])|(3,[],[])|(404,[11,28],[1.0...|  0.0|\n",
      "|       855.0|            99.0|(22,[11],[1.0])| (379,[64],[1.0])|(3,[],[])|(404,[11,86],[1.0...|  0.0|\n",
      "|      2045.0|           120.0|(22,[11],[1.0])|  (379,[6],[1.0])|(3,[],[])|(404,[11,28],[1.0...|  0.0|\n",
      "|      1500.0|           174.0|(22,[11],[1.0])|  (379,[1],[1.0])|(3,[],[])|(404,[11,23],[1.0...|  0.0|\n",
      "|      1655.0|            54.0|(22,[11],[1.0])| (379,[37],[1.0])|(3,[],[])|(404,[11,59],[1.0...|  0.0|\n",
      "|      1220.0|           137.0|(22,[11],[1.0])| (379,[13],[1.0])|(3,[],[])|(404,[11,35],[1.0...|  0.0|\n",
      "|       645.0|           157.0|(22,[13],[1.0])| (379,[36],[1.0])|(3,[],[])|(404,[13,58],[1.0...|  0.0|\n",
      "|      2010.0|            96.0|(22,[13],[1.0])|  (379,[9],[1.0])|(3,[],[])|(404,[13,31],[1.0...|  0.0|\n",
      "|       820.0|           122.0|(22,[13],[1.0])| (379,[86],[1.0])|(3,[],[])|(404,[13,108],[1....|  0.0|\n",
      "|      1359.0|            88.0|(22,[13],[1.0])|  (379,[3],[1.0])|(3,[],[])|(404,[13,25],[1.0...|  0.0|\n",
      "|      1515.0|           117.0|(22,[13],[1.0])| (379,[13],[1.0])|(3,[],[])|(404,[13,35],[1.0...|  0.0|\n",
      "|       640.0|            49.0|(22,[13],[1.0])| (379,[33],[1.0])|(3,[],[])|(404,[13,55],[1.0...|  0.0|\n",
      "+------------+----------------+---------------+-----------------+---------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# undersample majority data \n",
    "major_df = encodedData.filter(col(\"label\") == 0)\n",
    "minor_df = encodedData.filter(col(\"label\") == 1)\n",
    "ratio = major_df.count()/minor_df.count()\n",
    "print(\"ratio: {}\".format(ratio))\n",
    "\n",
    "sampled_majority_df = major_df.sample(False, 1/ratio)\n",
    "combined_df_2 = sampled_majority_df.unionAll(minor_df)\n",
    "combined_df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:======================================================> (29 + 1) / 30]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|  0.0|974141|\n",
      "|  1.0|973209|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check whether data is balanced \n",
    "combined_df_2.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>CRS_DEP_TIME</th><th>CRS_ELAPSED_TIME</th><th>OP_CARRIERVec</th><th>ORIGINVec</th><th>SEASONVec</th><th>features</th><th>label</th></tr>\n",
       "<tr><td>5.0</td><td>261.0</td><td>(22,[1],[1.0])</td><td>(379,[15],[1.0])</td><td>(3,[1],[1.0])</td><td>(404,[1,37,402],[...</td><td>0.0</td></tr>\n",
       "<tr><td>5.0</td><td>305.0</td><td>(22,[9],[1.0])</td><td>(379,[63],[1.0])</td><td>(3,[0],[1.0])</td><td>(404,[9,85,401],[...</td><td>0.0</td></tr>\n",
       "<tr><td>5.0</td><td>305.0</td><td>(22,[9],[1.0])</td><td>(379,[63],[1.0])</td><td>(3,[0],[1.0])</td><td>(404,[9,85,401],[...</td><td>0.0</td></tr>\n",
       "<tr><td>15.0</td><td>170.0</td><td>(22,[2],[1.0])</td><td>(379,[4],[1.0])</td><td>(3,[],[])</td><td>(404,[2,26],[1.0,...</td><td>0.0</td></tr>\n",
       "<tr><td>15.0</td><td>215.0</td><td>(22,[21],[1.0])</td><td>(379,[4],[1.0])</td><td>(3,[0],[1.0])</td><td>(404,[21,26,401],...</td><td>0.0</td></tr>\n",
       "<tr><td>20.0</td><td>200.0</td><td>(22,[2],[1.0])</td><td>(379,[7],[1.0])</td><td>(3,[0],[1.0])</td><td>(404,[2,29,401],[...</td><td>0.0</td></tr>\n",
       "<tr><td>20.0</td><td>200.0</td><td>(22,[2],[1.0])</td><td>(379,[7],[1.0])</td><td>(3,[0],[1.0])</td><td>(404,[2,29,401],[...</td><td>0.0</td></tr>\n",
       "<tr><td>20.0</td><td>200.0</td><td>(22,[2],[1.0])</td><td>(379,[7],[1.0])</td><td>(3,[0],[1.0])</td><td>(404,[2,29,401],[...</td><td>0.0</td></tr>\n",
       "<tr><td>20.0</td><td>211.0</td><td>(22,[21],[1.0])</td><td>(379,[4],[1.0])</td><td>(3,[1],[1.0])</td><td>(404,[21,26,402],...</td><td>0.0</td></tr>\n",
       "<tr><td>20.0</td><td>211.0</td><td>(22,[21],[1.0])</td><td>(379,[4],[1.0])</td><td>(3,[1],[1.0])</td><td>(404,[21,26,402],...</td><td>0.0</td></tr>\n",
       "<tr><td>20.0</td><td>211.0</td><td>(22,[21],[1.0])</td><td>(379,[4],[1.0])</td><td>(3,[1],[1.0])</td><td>(404,[21,26,402],...</td><td>0.0</td></tr>\n",
       "<tr><td>20.0</td><td>211.0</td><td>(22,[21],[1.0])</td><td>(379,[4],[1.0])</td><td>(3,[1],[1.0])</td><td>(404,[21,26,402],...</td><td>0.0</td></tr>\n",
       "<tr><td>20.0</td><td>215.0</td><td>(22,[21],[1.0])</td><td>(379,[4],[1.0])</td><td>(3,[0],[1.0])</td><td>(404,[21,26,401],...</td><td>0.0</td></tr>\n",
       "<tr><td>25.0</td><td>208.0</td><td>(22,[21],[1.0])</td><td>(379,[7],[1.0])</td><td>(3,[0],[1.0])</td><td>(404,[21,29,401],...</td><td>0.0</td></tr>\n",
       "<tr><td>25.0</td><td>214.0</td><td>(22,[21],[1.0])</td><td>(379,[7],[1.0])</td><td>(3,[],[])</td><td>(404,[21,29],[1.0...</td><td>0.0</td></tr>\n",
       "<tr><td>25.0</td><td>214.0</td><td>(22,[21],[1.0])</td><td>(379,[7],[1.0])</td><td>(3,[],[])</td><td>(404,[21,29],[1.0...</td><td>0.0</td></tr>\n",
       "<tr><td>25.0</td><td>240.0</td><td>(22,[16],[1.0])</td><td>(379,[31],[1.0])</td><td>(3,[0],[1.0])</td><td>(404,[16,53,401],...</td><td>0.0</td></tr>\n",
       "<tr><td>30.0</td><td>190.0</td><td>(22,[21],[1.0])</td><td>(379,[31],[1.0])</td><td>(3,[0],[1.0])</td><td>(404,[21,53,401],...</td><td>0.0</td></tr>\n",
       "<tr><td>30.0</td><td>197.0</td><td>(22,[9],[1.0])</td><td>(379,[63],[1.0])</td><td>(3,[],[])</td><td>(404,[9,85],[1.0,...</td><td>0.0</td></tr>\n",
       "<tr><td>30.0</td><td>197.0</td><td>(22,[9],[1.0])</td><td>(379,[63],[1.0])</td><td>(3,[1],[1.0])</td><td>(404,[9,85,402],[...</td><td>0.0</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+------------+----------------+---------------+----------------+-------------+--------------------+-----+\n",
       "|CRS_DEP_TIME|CRS_ELAPSED_TIME|  OP_CARRIERVec|       ORIGINVec|    SEASONVec|            features|label|\n",
       "+------------+----------------+---------------+----------------+-------------+--------------------+-----+\n",
       "|         5.0|           261.0| (22,[1],[1.0])|(379,[15],[1.0])|(3,[1],[1.0])|(404,[1,37,402],[...|  0.0|\n",
       "|         5.0|           305.0| (22,[9],[1.0])|(379,[63],[1.0])|(3,[0],[1.0])|(404,[9,85,401],[...|  0.0|\n",
       "|         5.0|           305.0| (22,[9],[1.0])|(379,[63],[1.0])|(3,[0],[1.0])|(404,[9,85,401],[...|  0.0|\n",
       "|        15.0|           170.0| (22,[2],[1.0])| (379,[4],[1.0])|    (3,[],[])|(404,[2,26],[1.0,...|  0.0|\n",
       "|        15.0|           215.0|(22,[21],[1.0])| (379,[4],[1.0])|(3,[0],[1.0])|(404,[21,26,401],...|  0.0|\n",
       "|        20.0|           200.0| (22,[2],[1.0])| (379,[7],[1.0])|(3,[0],[1.0])|(404,[2,29,401],[...|  0.0|\n",
       "|        20.0|           200.0| (22,[2],[1.0])| (379,[7],[1.0])|(3,[0],[1.0])|(404,[2,29,401],[...|  0.0|\n",
       "|        20.0|           200.0| (22,[2],[1.0])| (379,[7],[1.0])|(3,[0],[1.0])|(404,[2,29,401],[...|  0.0|\n",
       "|        20.0|           211.0|(22,[21],[1.0])| (379,[4],[1.0])|(3,[1],[1.0])|(404,[21,26,402],...|  0.0|\n",
       "|        20.0|           211.0|(22,[21],[1.0])| (379,[4],[1.0])|(3,[1],[1.0])|(404,[21,26,402],...|  0.0|\n",
       "|        20.0|           211.0|(22,[21],[1.0])| (379,[4],[1.0])|(3,[1],[1.0])|(404,[21,26,402],...|  0.0|\n",
       "|        20.0|           211.0|(22,[21],[1.0])| (379,[4],[1.0])|(3,[1],[1.0])|(404,[21,26,402],...|  0.0|\n",
       "|        20.0|           215.0|(22,[21],[1.0])| (379,[4],[1.0])|(3,[0],[1.0])|(404,[21,26,401],...|  0.0|\n",
       "|        25.0|           208.0|(22,[21],[1.0])| (379,[7],[1.0])|(3,[0],[1.0])|(404,[21,29,401],...|  0.0|\n",
       "|        25.0|           214.0|(22,[21],[1.0])| (379,[7],[1.0])|    (3,[],[])|(404,[21,29],[1.0...|  0.0|\n",
       "|        25.0|           214.0|(22,[21],[1.0])| (379,[7],[1.0])|    (3,[],[])|(404,[21,29],[1.0...|  0.0|\n",
       "|        25.0|           240.0|(22,[16],[1.0])|(379,[31],[1.0])|(3,[0],[1.0])|(404,[16,53,401],...|  0.0|\n",
       "|        30.0|           190.0|(22,[21],[1.0])|(379,[31],[1.0])|(3,[0],[1.0])|(404,[21,53,401],...|  0.0|\n",
       "|        30.0|           197.0| (22,[9],[1.0])|(379,[63],[1.0])|    (3,[],[])|(404,[9,85],[1.0,...|  0.0|\n",
       "|        30.0|           197.0| (22,[9],[1.0])|(379,[63],[1.0])|(3,[1],[1.0])|(404,[9,85,402],[...|  0.0|\n",
       "+------------+----------------+---------------+----------------+-------------+--------------------+-----+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split data into train and test\n",
    "train_df, test_df = combined_df_2.randomSplit([.8,.2],seed=1234)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol = 'features', labelCol='label')\n",
    "grid = ParamGridBuilder().addGrid(lr.maxIter, [0, 1]).build()\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "# cross validation\n",
    "# numFolds=3\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator, parallelism=2)\n",
    "cvModel = cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "predictions = cvModel.bestModel.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.630913013696873\n",
      "0.6292236298813869\n"
     ]
    }
   ],
   "source": [
    "#print evaluation metrics\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "print(evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"}))\n",
    "print(evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net, LASSO, RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression with elastic net, lasso, and ridge \n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol='label')\n",
    "grid = ParamGridBuilder().addGrid(lr.maxIter, [0, 1]).addGrid(lr.regParam, [0.1, 1, 10, 20, 50, 100]).addGrid(lr.elasticNetParam, [0, 0.1, 0.2, 0.3, 0.5, 0.7, 1]).build()\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "# cross validation\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator, parallelism=2)\n",
    "cvModel = cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "predictions = cvModel.bestModel.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6307488256707979\n",
      "0.6290733706775817\n"
     ]
    }
   ],
   "source": [
    "#print evaluation metrics\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "print(evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"}))\n",
    "print(evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/12 05:23:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1397.2 KiB\n",
      "22/03/12 05:24:13 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2010.3 KiB\n",
      "22/03/12 05:25:10 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "22/03/12 05:26:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "22/03/12 05:27:33 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "22/03/12 05:29:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.6 MiB\n",
      "22/03/12 05:30:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 6.9 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Set parameters for the Random Forest.\n",
    "rfc = RandomForestClassifier(maxDepth=10, numTrees=500, impurity=\"gini\", labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "# Fit the model to the data.\n",
    "rfcm = rfc.fit(train_df)\n",
    "\n",
    "# Given a dataset, predict each point's label, and show the results.\n",
    "predictions = rfcm.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/12 05:32:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6292901771154602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/12 05:35:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "[Stage 57:======================================================> (29 + 1) / 30]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6292455175913692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#print evaluation metrics\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "print(evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"}))\n",
    "print(evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
